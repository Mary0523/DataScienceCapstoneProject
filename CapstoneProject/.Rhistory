score_5e8_AI_Q, score_5e7_AI_Q, score_5e6_AI_Q, score_5e5_AI_Q, score_5e4_AI_Q, score_5e3_AI_Q, score_5e2_AI_Q, score_5e1_AI_Q)
for (i in 1:32){
var<-score[i]
print(var)
#summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + var, data = mega))
}
score<-c(score_5e8_CPD_Q, score_5e7_CPD_Q, score_5e6_CPD_Q, score_5e5_CPD_Q, score_5e4_CPD_Q, score_5e3_CPD_Q, score_5e2_CPD_Q, score_5e1_CPD_Q,
score_5e8_SI_Q, score_5e7_SI_Q, score_5e6_SI_Q, score_5e5_SI_Q, score_5e4_SI_Q, score_5e3_SI_Q, score_5e2_SI_Q, score_5e1_SI_Q,
score_5e8_SC_Q, score_5e7_SC_Q, score_5e6_SC_Q, score_5e5_SC_Q, score_5e4_SC_Q, score_5e3_SC_Q, score_5e2_SC_Q, score_5e1_SC_Q,
score_5e8_AI_Q, score_5e7_AI_Q, score_5e6_AI_Q, score_5e5_AI_Q, score_5e4_AI_Q, score_5e3_AI_Q, score_5e2_AI_Q, score_5e1_AI_Q)
score<-c("score_5e8_CPD_Q", "score_5e7_CPD_Q", "score_5e6_CPD_Q", "score_5e5_CPD_Q", "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
for (i in 1:32){
var<-score[i]
print(var)
summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + mega$var, data = mega))
}
for (i in 1:32){
var<-score[i]
print(var)
summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + score[i], data = mega))
}
for (i in 1:32){
var<-score[i]
print(var)
summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + score_5e8_CPD_Q, data = mega))
}
for (i in 1:32){
var<-score[i]
print(var)
summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + Score_5e8_CPD_Q, data = mega))
}
for (i in 1:32){
var<-score[i]
print(var)
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + Score_5e8_CPD_Q, data = mega)))
}
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q", "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
for (i in 1:32){
var<-score[i]
print(var)
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + score[i], data = mega)))
}
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q")#, "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
#"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
#"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
#"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
for (i in 1:32){
var<-score[i]
print(var)
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + score[i], data = mega)))
}
View(mega)
#"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
#"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
#"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
mega2<-mega[complete.cases(mega),]
for (i in 1:32){
var<-score[i]
print(var)
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + score[i], data = mega2)))
}
View(mega)
for (i in 11:18){
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + mega[i], data = mega)))
}
for (i in 11:18){
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + mega[,i], data = mega)))
}
for (i in 19:26){
name(mega[,i])
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + mega[,i], data = mega)))
}
for (i in 19:26){
names(mega[,i])
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + mega[,i], data = mega)))
}
for (i in 19:26){
print(names(mega[,i]))
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + mega[,i], data = mega)))
}
for (i in 19:26){
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + I(mega[,i]), data = mega)))
}
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q")#, "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
#"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
#"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
#"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
for (i in 1:4){
print(summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + I(score[i]), data = mega)))
}
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q")#, "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
#"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
#"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
#"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
print(summary(coxph(fmla, data = mega)))
}
?write.rtf
?write.csv
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q")#, "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
#"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
#"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
#"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
write.(print(summary(coxph(fmla, data = mega))),
file="//air/yinjiao_home/LiShiun_projects/Yinjiao/GSCAN_GWAS/results/mega_analysis_ARIC_COGEND_MESA_5e1/mega_analysis_R_results.csv",
append=T)
}
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
write.csv(print(summary(coxph(fmla, data = mega))),
file="//air/yinjiao_home/LiShiun_projects/Yinjiao/GSCAN_GWAS/results/mega_analysis_ARIC_COGEND_MESA_5e1/mega_analysis_R_results.csv",
append=T)
}
?write.txt
?write
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
write(print(summary(coxph(fmla, data = mega))),
file="//air/yinjiao_home/LiShiun_projects/Yinjiao/GSCAN_GWAS/results/mega_analysis_ARIC_COGEND_MESA_5e1/mega_analysis_R_results.txt",
append=T,sep="\t")
}
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
write(sum,
file="//air/yinjiao_home/LiShiun_projects/Yinjiao/GSCAN_GWAS/results/mega_analysis_ARIC_COGEND_MESA_5e1/mega_analysis_R_results.txt",
append=T,sep="\t")
}
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
#write(sum,
#file="//air/yinjiao_home/LiShiun_projects/Yinjiao/GSCAN_GWAS/results/mega_analysis_ARIC_COGEND_MESA_5e1/mega_analysis_R_results.txt",
#append=T,sep="\t")
return(sum)
}
sum
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
write(sum,
file="//air/yinjiao_home/LiShiun_projects/Yinjiao/GSCAN_GWAS/results/mega_analysis_ARIC_COGEND_MESA_5e1/mega_analysis_R_results.txt",
append=T)
}
str(sum)
coef(sum[,5])
hr <- round(coef(sum[,2],3)
)
coef(sum)
coef(sum)[7,]
coef(sum)[1]
coef(sum)[2]
sum$conf.int
coefpart1<-coef(sum)[7,]
coefpart2<-sum$conf.int[7,]
output<-cbind(coefpart1,coefpart2)
coefpart1
coefpart2
coefpart1<-as.dataframe(coef(sum)[7,])
coefpart1<-data.frame(coef(sum)[7,])
View(coefpart1)
coefpart1<-as.data.frame(coef(sum)[7,])
View(coefpart1)
coefpart1<-t(as.data.frame(coef(sum)[7,]))
coefpart2<-t(as.data.frmae(sum$conf.int[7,]))
coefpart2<-t(as.data.frame(sum$conf.int[7,]))
View(coefpart2)
coefpart2$exp(-coef)<-NULL
names(coefpart1)
colnames(coefpart1)
colnames(coefpart2)
coefpart2$exp(-coef)<-NULL
coefpart2[,2]<-NULL
coefpart2[,2]=NULL
cbind(coefpart1,coefpart2)
str(sum)
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q")#, "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
#"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
#"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
#"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
coefpart1<-t(as.data.frame(coef(sum)[7,]))
coefpart2<-t(as.data.frame(sum$conf.int[7,]))
coef<-cbind(coefpart1,coefpart2,sum$concordance[1],sum$concordance[2])
output<-rbind(output,coef)
}
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q")#, "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
#"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
#"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
#"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
output<-data.frame()
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
coefpart1<-t(as.data.frame(coef(sum)[7,]))
coefpart2<-t(as.data.frame(sum$conf.int[7,]))
coef<-cbind(coefpart1,coefpart2,sum$concordance[1],sum$concordance[2])
output<-rbind(output,coef)
}
View(output)
output<-data.frame()
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
coefpart1<-t(as.data.frame(coef(sum)[7,]))
coefpart2<-t(as.data.frame(sum$conf.int[7,]))
coef<-cbind(coefpart1,coefpart2,sum$concordance[1],sum$concordance[2],score[i])
output<-rbind(output,coef)
}
View(output)
View(output)
coxph.5e8.SC <- coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + Score_5e8_SC_Q, data = mega)
summary(coxph.5e8.SC)
coxph.5e7.SC <- coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + Score_5e7_SC_Q, data = mega)
summary(coxph.5e7.SC)
coxph.5e8.SC <- coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + Score_5e8_CPD_Q, data = mega)
summary(coxph.5e8.SC)
coxph.5e7.SC <- coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 + Score_5e7_CPD_Q, data = mega)
summary(coxph.5e7.SC)
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q", "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
output<-data.frame()
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
coefpart1<-t(as.data.frame(coef(sum)[7,]))
coefpart2<-t(as.data.frame(sum$conf.int[7,]))
coef<-cbind(coefpart1,coefpart2,sum$concordance[1],sum$concordance[2],score[i])
output<-rbind(output,coef)
}
View(output)
output[,2]<-NULL
View(output)
output[,6]<-NULL
head(output)
colnames(output)<-c("coef","se(coef)","z","P value","HR","lower95CI","upper95CI","Cstatistic","se(Cstatistic)","Var")
head(output)
View(output)
#base model
summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2,data=mega))
basesum<-summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2,data=mega))
output2<-rbind(output,c("NA","NA", "NA","NA", "NA","NA","NA",basesum$concordance[1],basesum$concordance[2],"base"))
output2<-rbind(output,c(NA,NA,NA,NA,NA,NA,NA,basesum$concordance[1],basesum$concordance[2],"base"))
str(output)
output[,7:9]<-as.numeric(output[,7:9])
output[,7:8]<-as.numeric(output[,7:8])
output[,7:8]<-as.numeric(as.character(output[,7:8]))
View(output)
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
coefpart1<-t(as.data.frame(coef(sum)[7,]))
coefpart2<-t(as.data.frame(sum$conf.int[7,]))
coef<-cbind(coefpart1,coefpart2,sum$concordance[1],sum$concordance[2],score[i])
output<-rbind(output,coef)
}
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q", "Score_5e5_CPD_Q", "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q", "score_5e1_CPD_Q",
"score_5e8_SI_Q", "score_5e7_SI_Q", "score_5e6_SI_Q", "score_5e5_SI_Q", "score_5e4_SI_Q", "score_5e3_SI_Q", "score_5e2_SI_Q", "score_5e1_SI_Q",
"score_5e8_SC_Q", "score_5e7_SC_Q", "score_5e6_SC_Q", "score_5e5_SC_Q", "score_5e4_SC_Q", "score_5e3_SC_Q", "score_5e2_SC_Q", "score_5e1_SC_Q",
"score_5e8_AI_Q", "score_5e7_AI_Q", "score_5e6_AI_Q", "score_5e5_AI_Q", "score_5e4_AI_Q", "score_5e3_AI_Q", "score_5e2_AI_Q", "score_5e1_AI_Q")
output<-data.frame()
for (i in 1:4){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
coefpart1<-t(as.data.frame(coef(sum)[7,]))
coefpart2<-t(as.data.frame(sum$conf.int[7,]))
coef<-cbind(coefpart1,coefpart2,sum$concordance[1],sum$concordance[2],score[i])
output<-rbind(output,coef)
}
View(output)
head(mega)
names(mega)
score<-c("Score_5e8_CPD_Q", "Score_5e7_CPD_Q", "Score_5e6_CPD_Q","Score_5e5_CPD_Q", "score_5e4_CPD_Q", "score_5e3_CPD_Q", "score_5e2_CPD_Q",
"score_5e1_CPD_Q", "Score_5e8_SI_Q", "Score_5e7_SI_Q",  "Score_5e6_SI_Q",  "Score_5e5_SI_Q",  "score_5e4_SI_Q",  "score_5e3_SI_Q",
"score_5e2_SI_Q",  "score_5e1_SI_Q", "Score_5e8_SC_Q",  "Score_5e7_SC_Q",  "Score_5e6_SC_Q",  "Score_5e5_SC_Q",  "score_5e4_SC_Q",
"score_5e3_SC_Q", "score_5e2_SC_Q",  "score_5e1_SC_Q",  "Score_5e8_AI_Q",  "Score_5e7_AI_Q",  "Score_5e6_AI_Q",  "Score_5e5_AI_Q",
"score_5e4_AI_Q",  "score_5e3_AI_Q",  "score_5e2_AI_Q",  "score_5e1_AI_Q")
output<-data.frame()
for (i in 1:length(score)){
fmla <- as.formula(paste0("Surv ~ age + factor(sex) + factor(study) + PC1 + PC2 +",score[i]))
sum<-summary(coxph(fmla, data = mega))
coefpart1<-t(as.data.frame(coef(sum)[7,]))
coefpart2<-t(as.data.frame(sum$conf.int[7,]))
coef<-cbind(coefpart1,coefpart2,sum$concordance[1],sum$concordance[2],score[i])
output<-rbind(output,coef)
}
View(output)
output[,2]<-NULL
output[,6]<-NULL
colnames(output)<-c("coef","se(coef)","z","P value","HR","lower95CI","upper95CI","Cstatistic","se(Cstatistic)","Var")
basesum<-summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2,data=mega))
base<-c(NA,NA,NA,NA,NA,NA,NA,basesum$concordance[1],basesum$concordance[2],"base")
base
base<-as.data.frame(c(NA,NA,NA,NA,NA,NA,NA,basesum$concordance[1],basesum$concordance[2],"base"))
colnames(base)<-c("coef","se(coef)","z","P value","HR","lower95CI","upper95CI","Cstatistic","se(Cstatistic)","Var")
base<-as.data.frame(c(basesum$concordance[1],basesum$concordance[2],"base"))
colnames(base)<-c("Cstatistic","se(Cstatistic)","Var")
View(base)
base<-t(as.data.frame(c(basesum$concordance[1],basesum$concordance[2],"base")))
colnames(base)<-c("Cstatistic","se(Cstatistic)","Var")
View(base)
base<-t(as.data.frame(c(NA,NA,NA,NA,NA,NA,NA,basesum$concordance[1],basesum$concordance[2],"base")))
colnames(base)<-c("coef","se(coef)","z","P value","HR","lower95CI","upper95CI","Cstatistic","se(Cstatistic)","Var")
View(base)
str(base)
basesum<-summary(coxph(Surv ~ age + factor(sex) + factor(study) + PC1 + PC2,data=mega))
base<-t(as.data.frame(c(NA,NA,NA,NA,NA,NA,NA,basesum$concordance[1],basesum$concordance[2],"base")))
colnames(base)<-c("coef","se(coef)","z","P value","HR","lower95CI","upper95CI","Cstatistic","se(Cstatistic)","Var")
base<-as.data.frame(base)
View(base)
output2<-rbind(output,base)
View(output2)
format.pval(output2$`P value`)
format.pval(output2$`P value`,missing=T)
View(output2)
write.csv(output2,file="//air/yinjiao_home/LiShiun_projects/Yinjiao/GSCAN_GWAS/results/mega_analysis_ARIC_COGEND_MESA_5e1/ARIC_COGEND_MESA_mega_R_output.csv",row.names = F)
?read.table
?sd
?write.csv
library(tm);library(NLP);library(R.utils); library(stringi);library(quanteda);library(readtext);library(stringr);library(SnowballC)
library(dplyr)
mytf4 <- readtext("C:/Users/may/Desktop/DataScience/Data_Science_Capstone/final/en_US/*.txt", cache = FALSE, encoding = "UTF-8")
corpus<-corpus(mytf4)
corpus_4gram<- tokens(corpus, what = "word", remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_separators = TRUE,
remove_twitter = TRUE, remove_hyphens = TRUE, remove_url = TRUE, ngrams = 4)
corpus_4gram_dfm<-dfm(corpus_4gram)
corpus_4gram_dfm<-dfm_sort(corpus_4gram_dfm)
corpus_4gram_dfm<-dfm_trim(corpus_4gram_dfm,min_termfreq=2)
#convert dfm to dataframe
Fourgram<-convert(corpus_4gram_dfm, to="data.frame")
Fourgram[1:3,1:5]
#remove unessesary column
Fourgram$document<-NULL
#calculate column freqencies
freq<-colSums(Fourgram)
head(freq)
#create a new data frame with words and frequncy
Fourgram_data <- data.frame(word=names(freq),frequency=freq)
Fourgram_data2<-Fourgram_data[with(Fourgram_data,order(-frequency)), ]
save(Fourgram_data2, file = "C:/Users/may/Desktop/DataScience/Data_Science_Capstone/final/en_US/four_gram.RData")
corpus<-corpus(mytf4)
corpus_3gram<- tokens(corpus, what = "word", remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_separators = TRUE,
remove_twitter = TRUE, remove_hyphens = TRUE, remove_url = TRUE, ngrams = 3)
corpus_3gram_dfm<-dfm(corpus_3gram)
topfeatures(corpus_3gram_dfm,20)
orpus_3gram_dfm<-dfm_sort(corpus_3gram_dfm)
corpus_3gram_dfm<-dfm_trim(corpus_3gram_dfm,min_termfreq=2)
#convert dfm to dataframe
Trigram<-convert(corpus_3gram_dfm, to="data.frame")
Trigram[1:3,1:5]
#remove unessesary column
Trigram$document<-NULL
#calculate column freqencies
freq<-colSums(Trigram)
head(freq)
#create a new data frame with words and frequncy
Trigram_data <- data.frame(word=names(freq),frequency=freq)
Trigram_data2<-Trigram_data[with(Trigram_data,order(-frequency)), ]
save(Trigram_data2, file = "C:/Users/may/Desktop/DataScience/Data_Science_Capstone/final/en_US/Tri_gram.RData")
corpus<-corpus(mytf4)
corpus_2gram<- tokens(corpus, what = "word", remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_separators = TRUE,
remove_twitter = TRUE, remove_hyphens = TRUE, remove_url = TRUE, ngrams = 2)
corpus_2gram_dfm<-dfm(corpus_2gram)
topfeatures(corpus_2gram_dfm,20)
corpus_2gram_dfm<-dfm_sort(corpus_2gram_dfm)
corpus_2gram_dfm<-dfm_trim(corpus_2gram_dfm,min_termfreq=2)
#convert dfm to dataframe
Bigram<-convert(corpus_2gram_dfm, to="data.frame")
Bigram[1:3,1:5]
#remove unessesary column
Bigram$document<-NULL
#calculate column freqencies
freq<-colSums(Bigram)
head(freq)
#create a new data frame with words and frequncy
Bigram_data <- data.frame(word=names(freq),frequency=freq)
Bigram_data2<-Bigram_data[with(Bigram_data,order(-frequency)), ]
save(Bigram_data2, file = "C:/Users/may/Desktop/DataScience/Data_Science_Capstone/final/en_US/Bi_gram.RData")
#one gram
corpus<-corpus(mytf4)
corpus_1gram<- tokens(corpus, what = "word", remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_separators = TRUE,
remove_twitter = TRUE, remove_hyphens = TRUE, remove_url = TRUE, ngrams = 1)
corpus_1gram_dfm<-dfm(corpus_1gram)
topfeatures(corpus_1gram_dfm,20)
corpus_1gram_dfm<-dfm_sort(corpus_1gram_dfm)
corpus_1gram_dfm<-dfm_trim(corpus_1gram_dfm,min_termfreq=2)
#convert dfm to dataframe
Unigram<-convert(corpus_1gram_dfm, to="data.frame")
Unigram[1:3,1:5]
#remove unessesary column
Unigram$document<-NULL
#calculate column freqencies
freq<-colSums(Unigram)
head(freq)
#create a new data frame with words and frequncy
Unigram_data <- data.frame(word=names(freq),frequency=freq)
Unigram_data2<-Unigram_data[with(Unigram_data,order(-frequency)), ]
save(Unigram_data2, file = "C:/Users/may/Desktop/DataScience/Data_Science_Capstone/final/en_US/Uni_gram.RData")
setwd("C:/Users/may/Desktop/DataScience/Data_Science_Capstone/final/en_US")
library(RWeka)
library(stringi)
library(tm)
library(ggplot2)
library(data.table)
library(SnowballC)
### Loading Data
blogs <- readLines("en_US.blogs.txt", encoding = "UTF-8", skipNul = TRUE)
news <- readLines("en_US.news.txt", encoding = "UTF-8", skipNul = TRUE)
twitter <- readLines("en_US.twitter.txt", encoding = "UTF-8", skipNul = TRUE)
### Clean and Sample Data
## Remove non-ASCII
blogs <- iconv(blogs, "latin1", "ASCII", sub="")
news <- iconv(news, "latin1", "ASCII", sub="")
twitter <- iconv(twitter, "latin1", "ASCII", sub="")
#Sampling Data
set.seed(1)
sample_data <- c(sample(blogs, length(blogs) * 0.03),
sample(news, length(news) * 0.03),
sample(twitter, length(twitter) * 0.03))
# Build corpus
corpus <- VCorpus(VectorSource(sample_data))
# Convert to lowercase
corpus <- tm_map(corpus, tolower)
# Remove punctuation
corpus <- tm_map(corpus, removePunctuation)
# Remove numbers
corpus <- tm_map(corpus, removeNumbers)
# Remove unneccesary white spaces
corpus <- tm_map(corpus, stripWhitespace)
# Plain text
corpus <- tm_map(corpus, PlainTextDocument)
### Tokenize and Calculate Frequencies of N-Grams
#Tokenize for uniqrams, bigrams, and trigrams.
uni_tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))
bi_tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
tri_tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
tetra_tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 4, max = 4))
#Build Term Document matrices of uniqrams, bigrams, and trigrams.
uni_matrix <- TermDocumentMatrix(corpus, control = list(tokenize = uni_tokenizer))
bi_matrix <- TermDocumentMatrix(corpus, control = list(tokenize = bi_tokenizer))
tri_matrix <- TermDocumentMatrix(corpus, control = list(tokenize = tri_tokenizer))
tetra_matrix <- TermDocumentMatrix(corpus, control = list(tokenize = tetra_tokenizer))
#Calculate frequency of n-grams
uni_corpus <- findFreqTerms(uni_matrix,lowfreq = 50)
bi_corpus <- findFreqTerms(bi_matrix,lowfreq=50)
tri_corpus <- findFreqTerms(tri_matrix,lowfreq=50)
tetra_corpus <- findFreqTerms(tetra_matrix,lowfreq=50)
uni_corpus_freq <- sort(rowSums(as.matrix(uni_matrix[uni_corpus,])), decreasing = TRUE)
uni_corpus_freq <- data.table(word=names(uni_corpus_freq), frequency=uni_corpus_freq)
bi_corpus_freq <- sort(rowSums(as.matrix(bi_matrix[bi_corpus,])), decreasing = TRUE)
bi_corpus_freq <- data.table(word=names(bi_corpus_freq), frequency=bi_corpus_freq)
tri_corpus_freq <- sort(rowSums(as.matrix(tri_matrix[tri_corpus,])), decreasing = TRUE)
tri_corpus_freq <- data.table(word=names(tri_corpus_freq), frequency=tri_corpus_freq)
tetra_corpus_freq <- sort(rowSums(as.matrix(tetra_matrix[tetra_corpus,])), decreasing = TRUE)
tetra_corpus_freq <- data.table(word=names(tetra_corpus_freq), frequency=tetra_corpus_freq)
setwd("C:/Users/may/Desktop/DataScience/Data_Science_Capstone/CapstoneProject/data")
saveRDS(uni_corpus_freq, file = "Uni_gram.rds")
saveRDS(bi_corpus_freq , file = "Bi_gram.rds")
saveRDS(tri_corpus_freq , file = "Tri_gram.rds")
saveRDS(tetra_corpus_freq , file = "four_gram.rds")
shiny::runApp('C:/Users/may/Desktop/DataScience/Data_Science_Capstone/CapstoneProject')
uni_corpus <- findFreqTerms(uni_matrix,lowfreq = 10)
bi_corpus <- findFreqTerms(bi_matrix,lowfreq=10)
tri_corpus <- findFreqTerms(tri_matrix,lowfreq=10)
tetra_corpus <- findFreqTerms(tetra_matrix,lowfreq=10)
uni_corpus_freq <- sort(rowSums(as.matrix(uni_matrix[uni_corpus,])), decreasing = TRUE)
uni_corpus_freq <- data.table(word=names(uni_corpus_freq), frequency=uni_corpus_freq)
bi_corpus_freq <- sort(rowSums(as.matrix(bi_matrix[bi_corpus,])), decreasing = TRUE)
bi_corpus_freq <- data.table(word=names(bi_corpus_freq), frequency=bi_corpus_freq)
tri_corpus_freq <- sort(rowSums(as.matrix(tri_matrix[tri_corpus,])), decreasing = TRUE)
tri_corpus_freq <- data.table(word=names(tri_corpus_freq), frequency=tri_corpus_freq)
tetra_corpus_freq <- sort(rowSums(as.matrix(tetra_matrix[tetra_corpus,])), decreasing = TRUE)
tetra_corpus_freq <- data.table(word=names(tetra_corpus_freq), frequency=tetra_corpus_freq)
bi_corpus <- findFreqTerms(bi_matrix,lowfreq=20)
bi_corpus_freq <- sort(rowSums(as.matrix(bi_matrix[bi_corpus,])), decreasing = TRUE)
bi_corpus_freq <- data.table(word=names(bi_corpus_freq), frequency=bi_corpus_freq)
setwd("C:/Users/may/Desktop/DataScience/Data_Science_Capstone/CapstoneProject/data")
saveRDS(uni_corpus_freq, file = "Uni_gram.rds")
saveRDS(bi_corpus_freq , file = "Bi_gram.rds")
saveRDS(tri_corpus_freq , file = "Tri_gram.rds")
saveRDS(tetra_corpus_freq , file = "four_gram.rds")
runApp('C:/Users/may/Desktop/DataScience/Data_Science_Capstone/CapstoneProject')
Unigram_data2<-readRDS("./data/Uni_gram.rds")
Bigram_data2<-readRDS("./data/Bi_gram.rds")
Trigram_data2<-readRDS("./data/Tri_gram.rds")
Fourgram_data2<-readRDS("./data/four_gram.rds")
setwd("C:/Users/may/Desktop/DataScience/Data_Science_Capstone/CapstoneProject")
runApp()
Unigram_data2<-readRDS("./data/Uni_gram.rds")
Bigram_data2<-readRDS("./data/Bi_gram.rds")
Trigram_data2<-readRDS("./data/Tri_gram.rds")
Fourgram_data2<-readRDS("./data/four_gram.rds")
View(Bigram_data2)
runApp()
runApp()
